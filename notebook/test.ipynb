{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerome.zhou/anaconda3/envs/predict_py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlen = 10\n",
    "klen = 10\n",
    "context_position = torch.arange(qlen, dtype=torch.long,\n",
    "                                        )[:, None]\n",
    "memory_position = torch.arange(klen, dtype=torch.long,\n",
    "                                      )[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [-1,  0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [-2, -1,  0,  1,  2,  3,  4,  5,  6,  7],\n",
       "        [-3, -2, -1,  0,  1,  2,  3,  4,  5,  6],\n",
       "        [-4, -3, -2, -1,  0,  1,  2,  3,  4,  5],\n",
       "        [-5, -4, -3, -2, -1,  0,  1,  2,  3,  4],\n",
       "        [-6, -5, -4, -3, -2, -1,  0,  1,  2,  3],\n",
       "        [-7, -6, -5, -4, -3, -2, -1,  0,  1,  2],\n",
       "        [-8, -7, -6, -5, -4, -3, -2, -1,  0,  1],\n",
       "        [-9, -8, -7, -6, -5, -4, -3, -2, -1,  0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_position - context_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.layers.relative_position_bias import RelativePositionBias\n",
    "\n",
    "pos_embed = RelativePositionBias(bidirectional=False,\n",
    "                                 num_buckets=20,\n",
    "                                 max_distance=10,\n",
    "                                 n_heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 10, 11, 12, 13, 14, 15, 16, 16, 17],\n",
       "        [ 1,  0, 10, 11, 12, 13, 14, 15, 16, 16],\n",
       "        [ 2,  1,  0, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [ 3,  2,  1,  0, 10, 11, 12, 13, 14, 15],\n",
       "        [ 4,  3,  2,  1,  0, 10, 11, 12, 13, 14],\n",
       "        [ 5,  4,  3,  2,  1,  0, 10, 11, 12, 13],\n",
       "        [ 6,  5,  4,  3,  2,  1,  0, 10, 11, 12],\n",
       "        [ 7,  6,  5,  4,  3,  2,  1,  0, 10, 11],\n",
       "        [ 7,  7,  6,  5,  4,  3,  2,  1,  0, 10],\n",
       "        [ 8,  7,  7,  6,  5,  4,  3,  2,  1,  0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed._relative_position_bucket(memory_position - context_position, bidirectional=True,\n",
    "                                    num_buckets=19, max_distance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3324, -1.4082, -0.0784,  0.9798],\n",
      "         [-1.5731,  2.0689,  0.8974,  1.5193],\n",
      "         [-0.4568,  0.1283,  0.5386, -2.4981],\n",
      "         [-1.6869,  0.1335,  0.8823, -0.2645]],\n",
      "\n",
      "        [[-0.6141,  0.9644, -0.2441, -1.4504],\n",
      "         [ 0.7161, -0.5827,  0.6977,  1.3610],\n",
      "         [ 0.8721, -0.4602,  1.0663,  0.3069],\n",
      "         [-1.1508, -0.7910,  1.0085, -0.4246]]])\n",
      "Max values: tensor([[-0.3324,  2.0689,  0.8974,  1.5193],\n",
      "        [ 0.8721,  0.9644,  1.0663,  1.3610]])\n",
      "Indices of max values: tensor([[0, 1, 1, 1],\n",
      "        [2, 0, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个三维张量，例如，大小为[2, 4, 4]\n",
    "x = torch.randn(2, 4, 4)\n",
    "\n",
    "# 在第二个维度（channels）上应用torch.max()\n",
    "values, indices = torch.max(x, dim=1)\n",
    "print(x)\n",
    "print(\"Max values:\", values)\n",
    "print(\"Indices of max values:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BN implement\n",
    "bn = nn.BatchNorm2d(num_features=3, eps=0, affine=False, track_running_stats=False)\n",
    "\n",
    "x = torch.rand(10, 3, 5, 5)* 10000\n",
    "offical_bn = bn(x)\n",
    "\n",
    "x_1 = x.permute(1,0,2,3).reshape(3,-1) # [c, n*h*w]\n",
    "mu_x = x_1.mean(dim=-1).view(1,3,1,1) # [1,c,1,1]\n",
    "std_x = x_1.std(dim=-1, unbiased=True).view(1,3,1,1)\n",
    "\n",
    "my_bn = (x-mu_x)/std_x # no epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.9740e-06)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(offical_bn-my_bn).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.7552,  0.8442,  0.1087,  0.4682],\n",
      "         [ 0.2172,  0.7370,  0.9776,  0.8823],\n",
      "         [-0.7359,  0.6933,  0.3336,  0.8447]]]), tensor([[[ 0.3748,  0.9994,  0.5744,  0.6639],\n",
      "         [-0.1345,  0.5654,  0.3115,  0.5989],\n",
      "         [-0.8560, -0.2329,  0.7621,  0.7718]]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "\n",
    "def precompute_freqs_cis(dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    # 计算词向量元素两两分组之后，每组元素对应的旋转角度\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "\n",
    "    # 生成 token 序列索引 t = [0, 1,..., seq_len-1]\n",
    "    t = torch.arange(seq_len, device=freqs.device)\n",
    "    # freqs.shape = [seq_len, dim // 2] \n",
    "    freqs = torch.outer(t, freqs).float()\n",
    "    # torch.polar的文档, https://pytorch.org/docs/stable/generated/torch.polar.html\n",
    "    # torch.polar输入参数是abs和angle，abs所有值都一样，abs和angle的shape都一样\n",
    "    # torch.polar输入参数是abs和angle，则freqs_cis = abs*(cos(angle) + sin(angle)i)\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    return freqs_cis\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    # xq.shape = [batch_size, seq_len, dim]\n",
    "    # xq_.shape = [batch_size, seq_len, dim // 2, 2] same as 2维情况\n",
    "    xq_ = xq.float().reshape(*xq.shape[:-1], -1, 2)\n",
    "    xk_ = xk.float().reshape(*xk.shape[:-1], -1, 2)\n",
    "    \n",
    "    # 转为复数域,  xq_.shape = [batch_size, seq_len, dim // 2]\n",
    "    xq_ = torch.view_as_complex(xq_)\n",
    "    xk_ = torch.view_as_complex(xk_)\n",
    "    # 应用旋转操作，然后将结果转回实数域\n",
    "    # xq_out.shape = [batch_size, seq_len, dim]\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(2) #从dim=2维度开始拍平\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(2)\n",
    "\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seq_len,dim=3,4\n",
    "    freqs_cis = precompute_freqs_cis(dim=dim, seq_len=seq_len, theta=10000.0)\n",
    "    xq = torch.rand(1, seq_len, dim)\n",
    "    xk = torch.rand(1, seq_len, dim)\n",
    "    res = apply_rotary_emb(xq, xk, freqs_cis)\n",
    "    # res的shape是1, seq_len, dim\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4a263d47b77ac32555f814086733849591fd88fece6a7709957ad496a0d751e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
